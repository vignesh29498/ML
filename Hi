import os
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Configuration: Define paths here
config = {
    'training_file_path': '/content/training_data.csv',  # Path to your training CSV
    'new_file_path': '/content/new_file.csv',  # Path to the new file for prediction
}

# Initialize the vectorizer
vectorizer = TfidfVectorizer(stop_words='english')

def load_training_data(training_file_path):
    """
    Load and preprocess training data from a CSV file.
    """
    df = pd.read_csv(training_file_path)
    
    # Ensure necessary columns exist
    if 'train_file_path' not in df.columns or 'match_file_path' not in df.columns:
        raise ValueError("CSV must contain 'train_file_path' and 'match_file_path' columns")

    # Extract file paths and corresponding match files
    train_file_paths = df['train_file_path'].dropna().unique()
    match_file_paths = df['match_file_path'].dropna().unique()
    
    if len(train_file_paths) != len(match_file_paths):
        raise ValueError("The number of training file paths must match the number of match file paths.")
    
    # Fit vectorizer on all training files
    all_texts = []
    for file_path in train_file_paths:
        if isinstance(file_path, str) and os.path.isfile(file_path):
            try:
                df = pd.read_csv(file_path)
                all_texts.extend(df.astype(str).apply(lambda x: ' '.join(x), axis=1))
            except Exception as e:
                print(f"Error reading file {file_path}: {e}")
        else:
            print(f"Invalid or missing file path: {file_path}")

    # Fit vectorizer on combined text data
    vectorizer.fit(all_texts)
    
    pattern_list = analyze_csv_files(train_file_paths)
    
    return pattern_list, match_file_paths

def analyze_csv_files(file_paths):
    """
    Analyze CSV files and extract patterns using TF-IDF vectorization.
    """
    pattern_list = []
    
    for file_path in file_paths:
        if isinstance(file_path, str) and os.path.isfile(file_path):
            try:
                df = pd.read_csv(file_path)
                pattern = extract_pattern_from_df(df)
                pattern_list.append((file_path, pattern))
            except Exception as e:
                print(f"Error processing file {file_path}: {e}")
        else:
            print(f"Invalid or missing file path: {file_path}")
    
    return pattern_list

def extract_pattern_from_df(df):
    """
    Extract patterns from DataFrame using TF-IDF vectorization.
    """
    df_str = df.astype(str).apply(lambda x: ' '.join(x), axis=1)
    tfidf_matrix = vectorizer.transform(df_str)  # Use transform instead of fit_transform
    pattern = tfidf_matrix.mean(axis=0)
    pattern_array = np.asarray(pattern).reshape(1, -1)  # Convert to NumPy array with consistent shape
    return pattern_array

def predict_file_name(new_file_path, pattern_list, match_file_paths):
    """
    Predict matching file name for a new file based on cosine similarity.
    """
    if isinstance(new_file_path, str) and os.path.isfile(new_file_path):
        try:
            new_df = pd.read_csv(new_file_path)
            new_pattern = extract_pattern_from_df(new_df)
            similarities = []
            
            for _, pattern in pattern_list:
                similarity = cosine_similarity(pattern, new_pattern)
                similarities.append(similarity)
            
            best_match_idx = np.argmax(similarities)
            return match_file_paths[best_match_idx]
        except Exception as e:
            print(f"Error predicting output for file {new_file_path}: {e}")
            return None
    else:
        print(f"Invalid or missing new file path: {new_file_path}")
        return None

if __name__ == "__main__":
    # Load and analyze training data
