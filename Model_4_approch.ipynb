{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVui7IFV6oMt",
        "outputId": "f469ff2d-da86-4498-fbb1-8e69dd80a53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Values from each column: ['USA', 515685321, 9.34, 'empty', 20241111, 'empty', 659455638, 'empty', 54596, 20241020, 'empty', 20243088, 'empty', '2022010112:20', 'empty', 'D', 'empty', 'empty', 'Y', 'empty', 'N', 'empty', 202410101530]\n",
            "Column Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def analyze_csv(file_path, max_rows=1000):\n",
        "    # Load the CSV file as strings to avoid automatic type conversion\n",
        "    df = pd.read_csv(file_path, dtype=str)\n",
        "\n",
        "    # Limit to first 1000 rows\n",
        "    df = df.head(max_rows)\n",
        "\n",
        "    # Initialize lists for random values and column indices\n",
        "    random_values = []\n",
        "    column_indices = []\n",
        "\n",
        "    # Get the list of column names\n",
        "    columns = df.columns.tolist()\n",
        "\n",
        "    for i, column in enumerate(columns):\n",
        "        column_data = df[column].dropna().tolist()\n",
        "\n",
        "        if not column_data:  # Skip empty columns\n",
        "            random_values.append(\"empty\")\n",
        "            column_indices.append(i)\n",
        "            continue\n",
        "\n",
        "        # Check if the column data can be converted to float or int\n",
        "        sample_value = column_data[0]\n",
        "        if is_float(sample_value):\n",
        "            column_data = [float(value) for value in column_data if is_float(value)]\n",
        "        elif is_int(sample_value):\n",
        "            column_data = [int(value) for value in column_data if is_int(value)]\n",
        "        else:\n",
        "            column_data = [str(value) for value in column_data]  # Convert to strings for non-numeric\n",
        "\n",
        "        # Take a random sample value\n",
        "        random_value = random.choice(column_data)\n",
        "        random_values.append(random_value)\n",
        "        column_indices.append(i)\n",
        "\n",
        "    return random_values, column_indices\n",
        "\n",
        "def is_float(value):\n",
        "    try:\n",
        "        float(value)\n",
        "        return '.' in str(value)  # Ensure it's a float by checking for decimal point\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def is_int(value):\n",
        "    try:\n",
        "        int(value)\n",
        "        return '.' not in str(value)  # Ensure it's an integer by checking for absence of decimal point\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/test.csv'\n",
        "random_values, column_indices = analyze_csv(file_path)\n",
        "\n",
        "# Print the results\n",
        "print(\"Random Values from each column:\", random_values)\n",
        "print(\"Column Indices:\", column_indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empty seprate"
      ],
      "metadata": {
        "id": "C4RVmPJRVSZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_empty_values(values, indices):\n",
        "    # Initialize lists to store matched and non-matched values and their indices\n",
        "    matched_values = []\n",
        "    matched_indices = []\n",
        "    non_matched_values = []\n",
        "    non_matched_indices = []\n",
        "\n",
        "    # Iterate over the values and indices\n",
        "    for value, index in zip(values, indices):\n",
        "        if value == 'empty':\n",
        "            matched_values.append(value)\n",
        "            matched_indices.append(index)\n",
        "        else:\n",
        "            non_matched_values.append(value)\n",
        "            non_matched_indices.append(index)\n",
        "\n",
        "    return matched_values, matched_indices, non_matched_values, non_matched_indices\n",
        "\n",
        "# Example usage\n",
        "values = random_values #['Country code', 'Indi', 'yes or no ', 'yes or no ', 'empty', 20241111.0, 'empty', 659455678.0, 'empty', '2022010112:19', 'empty']\n",
        "indices = column_indices #[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "matched_values, matched_indices, non_matched_values, non_matched_indices = separate_empty_values(values, indices)\n",
        "\n",
        "# Print the results\n",
        "print(\"Matched List:\", matched_values)\n",
        "print(\"Matched Indices:\", matched_indices)\n",
        "print(\"Non-Matched List:\", non_matched_values)\n",
        "print(\"Non-Matched Indices:\", non_matched_indices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ORAF_eFVSJJ",
        "outputId": "e386305b-6629-4487-8d71-564bea9e1d81"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched List: ['empty', 'empty', 'empty', 'empty', 'empty', 'empty', 'empty', 'empty', 'empty', 'empty']\n",
            "Matched Indices: [3, 5, 7, 10, 12, 14, 16, 17, 19, 21]\n",
            "Non-Matched List: ['USA', 515685321, 9.34, 20241111, 659455638, 54596, 20241020, 20243088, '2022010112:20', 'D', 'Y', 'N', 202410101530]\n",
            "Non-Matched Indices: [0, 1, 2, 4, 6, 8, 9, 11, 13, 15, 18, 20, 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_val=matched_values\n",
        "emp_ind=matched_indices\n",
        "print(emp_val)\n",
        "print(emp_ind)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L7cNPFVBJr_",
        "outputId": "26bb3cfe-7c80-40a7-cce8-1ca9e907149b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['empty', 'empty', 'empty', 'empty', 'empty', 'empty', 'empty', 'empty', 'empty', 'empty']\n",
            "[3, 5, 7, 10, 12, 14, 16, 17, 19, 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val=non_matched_values\n",
        "ind=non_matched_indices\n",
        "print(val)\n",
        "print(ind)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze34fkQ7VR-d",
        "outputId": "33d8fc09-db65-4e8d-f3ff-309ab933d3e7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['USA', 515685321, 9.34, 20241111, 659455638, 54596, 20241020, 20243088, '2022010112:20', 'D', 'Y', 'N', 202410101530]\n",
            "[0, 1, 2, 4, 6, 8, 9, 11, 13, 15, 18, 20, 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Know Value Check using ML"
      ],
      "metadata": {
        "id": "vaGAR4W-6qW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = '/content/knowxlsx.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Transpose the dataframe so that each value has an associated label\n",
        "df_t = df.set_index('label').T\n",
        "df_t = df_t.melt(var_name='label', value_name='value')\n",
        "\n",
        "# Drop missing values if any\n",
        "df_t.dropna(inplace=True)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "df_t['label_encoded'] = label_encoder.fit_transform(df_t['label'])\n",
        "\n",
        "# Save the label encoder for later use\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Encode the values using OneHotEncoder\n",
        "value_encoder = OneHotEncoder(sparse=False)\n",
        "X = value_encoder.fit_transform(df_t[['value']])\n",
        "\n",
        "# Save the value encoder for later use\n",
        "joblib.dump(value_encoder, 'value_encoder.pkl')\n",
        "\n",
        "y = df_t['label_encoded']\n",
        "\n",
        "#df_t.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnoOQL6W6v3m",
        "outputId": "ea267089-19a6-4fb7-bed8-19a78e55fa1a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Train the model\n",
        "model = KNeighborsClassifier(n_neighbors=1)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, 'trained_model.pkl')\n",
        "print(\"Model training completed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIhjaNGk6xwT",
        "outputId": "83d000a4-0eb8-4d35-f79e-ec6e5a97edca"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model and encoders\n",
        "model = joblib.load('trained_model.pkl')\n",
        "label_encoder = joblib.load('label_encoder.pkl')\n",
        "value_encoder = joblib.load('value_encoder.pkl')\n",
        "\n",
        "# Function to make predictions and handle unmatched values\n",
        "def predict_labels_and_handle_unmatched(values_list, indices_list):\n",
        "    matched_list = []\n",
        "    non_matched_list = []\n",
        "    matched_indices = []\n",
        "    non_matched_indices = []\n",
        "\n",
        "    for value, index in zip(values_list, indices_list):\n",
        "        # Check if the value exists in the encoder categories\n",
        "        if value in value_encoder.categories_[0]:\n",
        "            value_array = np.array([value]).reshape(-1, 1)\n",
        "            value_encoded = value_encoder.transform(value_array)\n",
        "            prediction = model.predict(value_encoded)\n",
        "            label = label_encoder.inverse_transform(prediction)[0]\n",
        "            matched_list.append(label)\n",
        "            matched_indices.append(index)\n",
        "        else:\n",
        "            non_matched_list.append(value)\n",
        "            non_matched_indices.append(index)\n",
        "\n",
        "    return matched_list, non_matched_list, matched_indices, non_matched_indices\n",
        "\n",
        "# Example usage\n",
        "values_list =val # ['USA', 155, 2546, 16545, 'vicjy', 'US']  # Replace with your list of values\n",
        "indices_list = ind #[0, 1, 2, 3, 4, 5]  # Replace with corresponding indices\n",
        "\n",
        "matched_list, non_matched_list, matched_indices, non_matched_indices = predict_labels_and_handle_unmatched(values_list, indices_list)\n",
        "\n",
        "# Print the results\n",
        "print(\"Matched List:\", matched_list)\n",
        "print(\"Non-Matched List:\", non_matched_list)\n",
        "print(\"Matched Indices:\", matched_indices)\n",
        "print(\"Non-Matched Indices:\", non_matched_indices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9bbiDWO60ze",
        "outputId": "78bd356e-9856-4763-c846-0dbcaa8fb144"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched List: ['Country code', 'Indi', 'yes or no ', 'yes or no ']\n",
            "Non-Matched List: [515685321, 9.34, 20241111, 659455638, 54596, 20241020, 20243088, '2022010112:20', 202410101530]\n",
            "Matched Indices: [0, 15, 18, 20]\n",
            "Non-Matched Indices: [1, 2, 4, 6, 8, 9, 11, 13, 22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=non_matched_list\n",
        "b=non_matched_indices\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NezZ2ZpM-H6",
        "outputId": "68945848-0da0-4484-d967-a729e8b6fcb2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[515685321, 9.34, 20241111, 659455638, 54596, 20241020, 20243088, '2022010112:20', 202410101530]\n",
            "[1, 2, 4, 6, 8, 9, 11, 13, 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c=matched_list\n",
        "d=matched_indices\n",
        "print(c)\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfVYDP0tUMnS",
        "outputId": "3507f852-98b2-45e9-e460-ac17031d57dd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Country code', 'Indi', 'yes or no ', 'yes or no ']\n",
            "[0, 15, 18, 20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date prediction"
      ],
      "metadata": {
        "id": "-i4QYSraJMlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "import re\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/date.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Enhanced date format checking\n",
        "def is_date_format(value):\n",
        "    value = str(value)\n",
        "    try:\n",
        "        if len(value) == 8 and value.isdigit():\n",
        "            pd.to_datetime(value, format='%Y%m%d', errors='raise')\n",
        "            return True\n",
        "        elif len(value) == 12 and value.isdigit():\n",
        "            pd.to_datetime(value, format='%Y%m%d%H%M', errors='raise')\n",
        "            return True\n",
        "        elif len(value) == 13 and value[8:10] == ':' and value[:8].isdigit() and value[9:].isdigit():\n",
        "            pd.to_datetime(value, format='%Y%m%d%H:%M', errors='raise')\n",
        "            return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "    return False\n",
        "\n",
        "def is_numeric(value):\n",
        "    return value.isdigit()\n",
        "\n",
        "def has_special_chars(value):\n",
        "    return bool(re.search(r'[^\\w\\s]', value))\n",
        "\n",
        "def is_alpha(value):\n",
        "    return value.isalpha()\n",
        "\n",
        "# Feature extraction function\n",
        "def extract_features(values):\n",
        "    values = values.astype(str)  # Ensure all values are strings\n",
        "    features = pd.DataFrame()\n",
        "    features['length'] = values.apply(len)\n",
        "    features['is_date_format'] = values.apply(is_date_format)\n",
        "    features['is_numeric'] = values.apply(is_numeric)\n",
        "    features['has_special_chars'] = values.apply(has_special_chars)\n",
        "    features['is_alpha'] = values.apply(is_alpha)\n",
        "    return features\n",
        "\n",
        "# Prepare features and labels\n",
        "X_features = extract_features(df['value'])\n",
        "y = df['label']\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the model and encoder\n",
        "joblib.dump(model, '/content/date_classifier_model.pkl')\n",
        "joblib.dump(label_encoder, '/content/label_encoder.pkl')\n"
      ],
      "metadata": {
        "id": "TnHSyDnUDicT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d8fcaa-3c81-4dea-88f3-45a80e5070f9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           5       0.00      0.00      0.00       0.0\n",
            "           8       0.00      0.00      0.00       1.0\n",
            "           9       0.00      0.00      0.00       1.0\n",
            "          11       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00       3.0\n",
            "   macro avg       0.00      0.00      0.00       3.0\n",
            "weighted avg       0.00      0.00      0.00       3.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import re\n",
        "\n",
        "# Load the model and encoder\n",
        "model = joblib.load('/content/date_classifier_model.pkl')\n",
        "label_encoder = joblib.load('/content/label_encoder.pkl')\n",
        "\n",
        "# Define the feature extraction function (same as used in training)\n",
        "def extract_features(values):\n",
        "    values = values.astype(str)  # Ensure all values are strings\n",
        "    features = pd.DataFrame()\n",
        "    features['length'] = values.apply(len)\n",
        "    features['is_date_format'] = values.apply(is_date_format)\n",
        "    features['is_numeric'] = values.apply(is_numeric)\n",
        "    features['has_special_chars'] = values.apply(has_special_chars)\n",
        "    features['is_alpha'] = values.apply(is_alpha)\n",
        "    return features\n",
        "\n",
        "# Define function to check if a value is a date format\n",
        "def is_date_format(value):\n",
        "    value = str(value)\n",
        "    if value == '':\n",
        "        return False\n",
        "    try:\n",
        "        if len(value) == 8 and value.isdigit():\n",
        "            pd.to_datetime(value, format='%Y%m%d', errors='raise')\n",
        "            return True\n",
        "        elif len(value) == 12 and value.isdigit():\n",
        "            pd.to_datetime(value, format='%Y%m%d%H%M', errors='raise')\n",
        "            return True\n",
        "        elif len(value) == 13 and value[8:10] == ':' and value[:8].isdigit() and value[9:].isdigit():\n",
        "            pd.to_datetime(value, format='%Y%m%d%H:%M', errors='raise')\n",
        "            return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "    return False\n",
        "\n",
        "def is_numeric(value):\n",
        "    return value.isdigit()\n",
        "\n",
        "def has_special_chars(value):\n",
        "    return bool(re.search(r'[^\\w\\s]', value))\n",
        "\n",
        "def is_alpha(value):\n",
        "    return value.isalpha()\n",
        "\n",
        "# New values to predict\n",
        "input_values = a #['20241010', '202410101530', '20241010:15', 'AB458622', '659455560', '']  # Example input including empty value\n",
        "input_indices = b #[0, 1, 2, 3, 4, 5]  # Corresponding indices\n",
        "\n",
        "new_values = pd.Series(input_values)\n",
        "\n",
        "# Initialize lists for matched and non-matched values and indices\n",
        "matched_list = []\n",
        "non_matched_list = []\n",
        "matched_indices = []\n",
        "non_matched_indices = []\n",
        "\n",
        "# Iterate over values, predictions, and indices\n",
        "for index, value in zip(input_indices, new_values):\n",
        "    if value == '':\n",
        "        non_matched_list.append(value)  # Add empty values to non-matched list\n",
        "        non_matched_indices.append(index)\n",
        "        continue\n",
        "\n",
        "    # Extract features for non-empty values\n",
        "    X_new_features = extract_features(pd.Series([value]))\n",
        "\n",
        "    # Predict\n",
        "    y_new_pred = model.predict(X_new_features)\n",
        "    predicted_label = label_encoder.inverse_transform(y_new_pred)[0]\n",
        "\n",
        "    if is_date_format(value):\n",
        "        matched_list.append(predicted_label)\n",
        "        matched_indices.append(index)\n",
        "    else:\n",
        "        non_matched_list.append(value)\n",
        "        non_matched_indices.append(index)\n",
        "\n",
        "# Print results\n",
        "print(f\"Matched List: {matched_list}\")\n",
        "print(f\"Non-Matched List: {non_matched_list}\")\n",
        "print(f\"Matched Indices: {matched_indices}\")\n",
        "print(f\"Non-Matched Indices: {non_matched_indices}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XX_thsk6il3",
        "outputId": "ccc98301-3af7-4ed8-ffdf-1c446dd92dce"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched List: ['date4', 'date4', 'date2']\n",
            "Non-Matched List: [515685321, 2.96, 659455596, 54595, 20243025, '2022010112:14']\n",
            "Matched Indices: [4, 9, 22]\n",
            "Non-Matched Indices: [1, 2, 6, 8, 11, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e=matched_list\n",
        "f=matched_indices\n",
        "print(e)\n",
        "print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbCVNlkDJXHW",
        "outputId": "c6af1e22-9a03-48c2-f661-5bc96a0bb427"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['date4', 'date4', 'date2']\n",
            "[4, 9, 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g=non_matched_list\n",
        "h=non_matched_indices\n",
        "print(g)\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ1oeoNgUBcI",
        "outputId": "419ca1da-1b73-4459-8287-684518c2d60e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[515685321, 2.96, 659455596, 54595, 20243025, '2022010112:14']\n",
            "[1, 2, 6, 8, 11, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str_li=[str(item) for item in g]\n",
        "print(str_li)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd_SzPxs6KCO",
        "outputId": "83609ad4-1a3c-4d16-bda2-a859b725603e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['515685321', '2.96', '659455596', '54595', '20243025', '2022010112:14']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load training data from CSV\n",
        "file_path = '/content/dataset_1.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "#print(\"Loaded Data:\")\n",
        "#print(df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Feature extraction using .apply\n",
        "df['length'] = df['value'].apply(len)\n",
        "df['is_numeric_dm'] = df['value'].apply(lambda x: int(x.isdigit()))\n",
        "df['is_alphabetic_dm'] = df['value'].apply(lambda x: int(x.isalpha()))\n",
        "df['is_alphanumeric_dm'] = df['value'].apply(lambda x: int(x.isalnum()))\n",
        "df['has_hyphen_dm'] = df['value'].apply(lambda x: int('-' in x))\n",
        "df['has_letters_dm'] = df['value'].apply(lambda x: int(any(c.isalpha() for c in x)))\n",
        "df['has_numbers_dm'] = df['value'].apply(lambda x: int(any(c.isdigit() for c in x)))\n",
        "df['has_spaces_dm'] = df['value'].apply(lambda x: int(any(c.isspace() for c in x)))\n",
        "df['has_special_chars_dm'] = df['value'].apply(lambda x: int(bool(re.search('[^a-zA-Z0-9\\s]', x))))\n",
        "\n",
        "df['is_numeric_re'] = df['value'].apply(lambda x: int(bool(re.match('^\\d+$', x))))\n",
        "df['is_alphabetic_re'] = df['value'].apply(lambda x: int(bool(re.match('^[a-zA-Z]+$', x))))\n",
        "df['is_alphanumeric_re'] = df['value'].apply(lambda x: int(bool(re.match('^[a-zA-Z0-9]+$', x))))\n",
        "df['has_hyphen_re'] = df['value'].apply(lambda x: int(bool(re.search('-', x))))\n",
        "df['has_letters_re'] = df['value'].apply(lambda x: int(bool(re.search('[a-zA-Z]', x))))\n",
        "df['has_numbers_re'] = df['value'].apply(lambda x: int(bool(re.search('[0-9]', x))))\n",
        "df['has_spaces_re'] = df['value'].apply(lambda x: int(bool(re.search('\\s', x))))\n",
        "df['has_special_chars_re'] = df['value'].apply(lambda x: int(bool(re.search('[^a-zA-Z0-9\\s]', x))))\n",
        "df['is_exactly_3_digits'] = df['value'].apply(lambda x: int(bool(re.match('^\\d{3}$', x))))\n",
        "\n",
        "#print(\"Extracted Features:\")\n",
        "#print(df.head())\n",
        "\n",
        "# Combine all features into a single DataFrame\n",
        "combined_features = df[[\n",
        "    'length',\n",
        "    'is_numeric_dm', 'is_alphabetic_dm', 'is_alphanumeric_dm', 'has_hyphen_dm', 'has_letters_dm', 'has_numbers_dm', 'has_spaces_dm', 'has_special_chars_dm',\n",
        "    'is_numeric_re', 'is_alphabetic_re', 'is_alphanumeric_re', 'has_hyphen_re', 'has_letters_re', 'has_numbers_re', 'has_spaces_re', 'has_special_chars_re',\n",
        "    'is_exactly_3_digits'\n",
        "]]\n",
        "\n",
        "#print(\"Combined Features for Model Training:\")\n",
        "#print(combined_features)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(df['label'])\n",
        "#print(\"Encoded Labels:\")\n",
        "#print(y_encoded)\n",
        "#print(\"Label Distribution:\")\n",
        "#print(pd.Series(y_encoded).value_counts())\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train.values, y_train)).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test.values, y_test)).batch(32)\n",
        "\n",
        "\n",
        "# Build a simple neural network model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(combined_features.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_dataset, epochs=10, validation_data=test_dataset)\n",
        "\n",
        "import pickle\n",
        "# Save the trained model and label encoder to local files\n",
        "model.save('tf_model.h5')\n",
        "\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "print(\"Model and label encoder saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmxgSqZu7Q03",
        "outputId": "5118aa11-4aa3-4eed-8e6a-8d1bc8552150"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 2.0328 - val_accuracy: 0.5000 - val_loss: 1.3783\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1.9594 - val_accuracy: 0.5000 - val_loss: 1.4829\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1.8916 - val_accuracy: 0.5000 - val_loss: 1.5859\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2500 - loss: 1.8295 - val_accuracy: 0.0000e+00 - val_loss: 1.6936\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2500 - loss: 1.7718 - val_accuracy: 0.0000e+00 - val_loss: 1.8066\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5000 - loss: 1.7182 - val_accuracy: 0.0000e+00 - val_loss: 1.9215\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5000 - loss: 1.6686 - val_accuracy: 0.0000e+00 - val_loss: 2.0382\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 1.6240 - val_accuracy: 0.0000e+00 - val_loss: 2.1571\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 1.5829 - val_accuracy: 0.0000e+00 - val_loss: 2.2741\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 1.5464 - val_accuracy: 0.0000e+00 - val_loss: 2.3908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and label encoder saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str_li"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVqybeB1Nc45",
        "outputId": "521e7323-05fa-434f-9025-6bc0928a4cb9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['515685321', '2.96', '659455596', '54595', '20243025', '2022010112:14']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model and label encoder\n",
        "model = tf.keras.models.load_model('tf_model.h5')\n",
        "\n",
        "with open('label_encoder.pkl', 'rb') as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "# Manually provided list of data for prediction\n",
        "data_to_predict = str_li #['654321', 'B123456789', '5678123456789', '6789', '3D4F5H', '666-7890', '490', '400']\n",
        "\n",
        "# Prepare features for prediction using .apply\n",
        "predict_df = pd.DataFrame(data_to_predict, columns=['value'])\n",
        "\n",
        "predict_df['length'] = predict_df['value'].apply(len)\n",
        "predict_df['is_numeric_dm'] = predict_df['value'].apply(lambda x: int(x.isdigit()))\n",
        "predict_df['is_alphabetic_dm'] = predict_df['value'].apply(lambda x: int(x.isalpha()))\n",
        "predict_df['is_alphanumeric_dm'] = predict_df['value'].apply(lambda x: int(x.isalnum()))\n",
        "predict_df['has_hyphen_dm'] = predict_df['value'].apply(lambda x: int('-' in x))\n",
        "predict_df['has_letters_dm'] = predict_df['value'].apply(lambda x: int(any(c.isalpha() for c in x)))\n",
        "predict_df['has_numbers_dm'] = predict_df['value'].apply(lambda x: int(any(c.isdigit() for c in x)))\n",
        "predict_df['has_spaces_dm'] = predict_df['value'].apply(lambda x: int(any(c.isspace() for c in x)))\n",
        "predict_df['has_special_chars_dm'] = predict_df['value'].apply(lambda x: int(bool(re.search('[^a-zA-Z0-9\\s]', x))))\n",
        "\n",
        "predict_df['is_numeric_re'] = predict_df['value'].apply(lambda x: int(bool(re.match('^\\d+$', x))))\n",
        "predict_df['is_alphabetic_re'] = predict_df['value'].apply(lambda x: int(bool(re.match('^[a-zA-Z]+$', x))))\n",
        "predict_df['is_alphanumeric_re'] = predict_df['value'].apply(lambda x: int(bool(re.match('^[a-zA-Z0-9]+$', x))))\n",
        "predict_df['has_hyphen_re'] = predict_df['value'].apply(lambda x: int(bool(re.search('-', x))))\n",
        "predict_df['has_letters_re'] = predict_df['value'].apply(lambda x: int(bool(re.search('[a-zA-Z]', x))))\n",
        "predict_df['has_numbers_re'] = predict_df['value'].apply(lambda x: int(bool(re.search('[0-9]', x))))\n",
        "predict_df['has_spaces_re'] = predict_df['value'].apply(lambda x: int(bool(re.search('\\s', x))))\n",
        "predict_df['has_special_chars_re'] = predict_df['value'].apply(lambda x: int(bool(re.search('[^a-zA-Z0-9\\s]', x))))\n",
        "predict_df['is_exactly_3_digits'] = predict_df['value'].apply(lambda x: int(bool(re.match('^\\d{3}$', x))))\n",
        "\n",
        "# Select features for prediction\n",
        "X_input = predict_df[[\n",
        "    'length',\n",
        "    'is_numeric_dm', 'is_alphabetic_dm', 'is_alphanumeric_dm', 'has_hyphen_dm', 'has_letters_dm', 'has_numbers_dm', 'has_spaces_dm', 'has_special_chars_dm',\n",
        "    'is_numeric_re', 'is_alphabetic_re', 'is_alphanumeric_re', 'has_hyphen_re', 'has_letters_re', 'has_numbers_re', 'has_spaces_re', 'has_special_chars_re',\n",
        "    'is_exactly_3_digits'\n",
        "]]\n",
        "\n",
        "# Make predictions with the TensorFlow model\n",
        "rf_predictions = model.predict(X_input)\n",
        "rf_predictions = tf.argmax(rf_predictions, axis=1).numpy()\n",
        "\n",
        "# Decode label predictions\n",
        "predicted_labels = le.inverse_transform(rf_predictions)\n",
        "pred=[]\n",
        "# Print prediction results\n",
        "for value, label in zip(data_to_predict, predicted_labels):\n",
        "    #print(f\"Input Data: {value} -> Prediction: {label}\")\n",
        "    pred.append(label)\n",
        "#pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMVpyU258YwY",
        "outputId": "c03ce815-fed1-417d-e5a4-bdf3f4f02767"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E12_VMOw8eRc",
        "outputId": "408c1305-d81e-4b59-f95d-2e184296a61d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tax', 'tax', 'tax', 'balance', 'tax', 'tax']\n",
            "[1, 2, 6, 8, 11, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Given lists\n",
        "values1 = pred # ['tax', 'tax', 'tax', 'balance', 'tax', 'tax']\n",
        "indices1 = h #[1, 2, 6, 8, 11, 13]\n",
        "\n",
        "values2 = e #['date4', 'date4', 'date2']\n",
        "indices2 = f # [4, 9, 22]\n",
        "\n",
        "values3 = c #['Country code', 'Indi', 'yes or no', 'yes or no']\n",
        "indices3 = d #[0, 15, 18, 20]\n",
        "\n",
        "values4 = ['empty'] * len(emp_ind)\n",
        "indices4 = emp_ind #[3, 5, 7, 10, 12, 14, 16, 17, 19, 21]\n",
        "\n",
        "# Combine all values and indices\n",
        "all_values = values1 + values2 + values3 + values4\n",
        "all_indices = indices1 + indices2 + indices3 + indices4\n",
        "\n",
        "# Determine the length of the final list\n",
        "max_index = max(all_indices)\n",
        "final_list = [''] * (max_index + 1)\n",
        "\n",
        "# Place the values in the final list at the respective indices\n",
        "for value, index in zip(all_values, all_indices):\n",
        "    final_list[index] = value\n",
        "\n",
        "print(final_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "lkb8FgQF-WT6",
        "outputId": "8ca332f9-9fe8-4503-b34b-994de7b6f22d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can only concatenate list (not \"_io.BufferedReader\") to list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-4f2f000960a3>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Combine all values and indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mall_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalues2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalues3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalues4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mall_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindices2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindices3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mindices4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Determine the length of the final list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"_io.BufferedReader\") to list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Given lists\n",
        "pred = ['tax', 'tax', 'tax', 'balance', 'tax', 'tax']\n",
        "h = [1, 2, 6, 8, 11, 13]\n",
        "\n",
        "e = ['date4', 'date4', 'date2']\n",
        "f = [4, 9, 22]\n",
        "\n",
        "c = ['Country code', 'Indi', 'yes or no', 'yes or no']\n",
        "d = [0, 15, 18, 20]\n",
        "\"\"\"\n",
        "emp_ind # = [3, 5, 7, 10, 12, 14, 16, 17, 19, 21]\n",
        "values4 = ['empty'] * len(emp_ind)\n",
        "indices4 = emp_ind\n",
        "\n",
        "# Combine all values and indices\n",
        "all_values = pred + e + c + values4\n",
        "all_indices = h + f + d + indices4\n",
        "\n",
        "# Determine the length of the final list\n",
        "max_index = max(all_indices)\n",
        "final_list = [''] * (max_index + 1)\n",
        "\n",
        "# Place the values in the final list at the respective indices\n",
        "for value, index in zip(all_values, all_indices):\n",
        "    final_list[index] = value\n",
        "\n",
        "print(final_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBNQbB7CCDeN",
        "outputId": "44b43a33-061a-4678-bc20-12f705259a9b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Country code', 'tax', 'tax', 'empty', 'date4', 'empty', 'tax', 'empty', 'balance', 'date4', 'empty', 'tax', 'empty', 'tax', 'empty', 'Indi', 'empty', 'empty', 'yes or no', 'empty', 'yes or no', 'empty', 'date2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wicNkkLaCkgv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}